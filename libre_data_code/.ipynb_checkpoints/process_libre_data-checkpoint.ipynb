{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51fe9044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "807f4f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols = list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc5b94b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_transform(load_path, save_path, inVal_unit, outVal, days_of_training = 4, rowLimit = None):\n",
    "    \n",
    "    libre_files = glob.glob(f\"{load_path}/*\")\n",
    "    print(len(libre_files))\n",
    "    \n",
    "    file_n = 1\n",
    "    \n",
    "    for f in libre_files:\n",
    "        print(f)\n",
    "        series = read_csv(f, header=0, index_col=1, nrows = rowLimit)\n",
    "        values = series.values\n",
    "\n",
    "        # values = values[0:20000]\n",
    "\n",
    "        for j in range(1, (days_of_training + 1)):\n",
    "            # transform the time series data into supervised learning\n",
    "            inVal  = inVal_unit*j\n",
    "            outVal = outVal\n",
    "            data = series_to_supervised(values, n_in=inVal, n_out = outVal)\n",
    "\n",
    "            # save out data as supervised data format\n",
    "            np.savetxt(f\"{save_path}/supervised_{file_n}_{inVal}_{outVal}_vals.csv\", data, delimiter=\",\")\n",
    "\n",
    "        file_n = file_n + 1\n",
    "        \n",
    "    return(len(libre_files))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67833e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_labeled_data(load_path, rowLimit, n_files, train_bins, test_bins, gap_bins, outVal, hypo_thresh, prevelance_ratio):\n",
    "    \n",
    "    for i in range(1, n_files+1):\n",
    "        # print(i)\n",
    "        sub = pd.read_csv(f\"{load_path}/supervised_{i}_{train_bins}_{outVal}_vals.csv\",\n",
    "                     nrows = rowLimit, header = None)\n",
    "\n",
    "        if i==1:\n",
    "            concat_output = sub\n",
    "        else:\n",
    "            frames = [concat_output, sub]\n",
    "            concat_output = pd.concat(frames)\n",
    "            \n",
    "    print(concat_output.shape)\n",
    "    \n",
    "    # take every nth row; where n = test_bins\n",
    "    all_data = concat_output.iloc[::test_bins, :]\n",
    "\n",
    "    # divide into train and test splits (cols)\n",
    "    train_cols = all_data.iloc[:, 0:train_bins]\n",
    "    test_cols  = all_data.iloc[:, train_bins:train_bins + test_bins + gap_bins]\n",
    "    \n",
    "    # create labels\n",
    "    minvalue = test_cols.min(axis = 1)\n",
    "    label = np.where(minvalue < hypo_thresh, 1, 0)\n",
    "\n",
    "    df_X = train_cols.copy()\n",
    "    df_X['label'] = label\n",
    "    \n",
    "    # downsample to a specified ratio of case:control\n",
    "    df_X_case = df_X[label==1]\n",
    "    df_X_control = df_X[label==0]\n",
    "\n",
    "    sample = df_X_control.sample(n=(df_X_case.shape[0] * prevelance_ratio))\n",
    "\n",
    "    frame = [df_X_case, sample]\n",
    "    output_frame = pd.concat(frame)\n",
    "    \n",
    "    return(output_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6200c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_6.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_7.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_5.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_4.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_1.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_3.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_2.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_14.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_15.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_11.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_10.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_12.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_13.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_9.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_8.csv\n"
     ]
    }
   ],
   "source": [
    "# transform a time series dataset into a supervised learning dataset\n",
    "# return the number of source files (sourceFile_n)\n",
    "# (ie individuals libre data in the processed raw data folder (load_path))\n",
    "sourceFile_n = load_and_transform(load_path = \"/media/psf/Home/Documents/data/processed_libre\",\n",
    "                  save_path = \"/media/psf/Home/Documents/data/libre_as_supervised2\",\n",
    "                  inVal_unit = 96,\n",
    "                  outVal = 96,\n",
    "                  days_of_training = 4,\n",
    "                  rowLimit = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aad2c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the supervised files and concatenate into a single file\n",
    "# select by nth row to avoid overfitting / data leakage from one training set into another\n",
    "# take interval to be duration of test window\n",
    "# add progressive gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e6b864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables\n",
    "sourceFile_n = 15 # if all cells not run above ie if starting here need to set this\n",
    "\n",
    "n_files = sourceFile_n\n",
    "\n",
    "test_duration_hours = 4\n",
    "gap_hours = 0\n",
    "\n",
    "train_bins = 192\n",
    "test_bins = test_duration_hours * 4\n",
    "gap_bins = gap_hours * 4\n",
    "\n",
    "hypo_thresh = 3\n",
    "\n",
    "prevelance_ratio = 1\n",
    "\n",
    "# concatenate the data files, add label\n",
    "data_lab = generate_labeled_data(\"/media/psf/Home/Documents/data/libre_as_supervised\",\n",
    "                                 None,\n",
    "                                 n_files,\n",
    "                                 train_bins,\n",
    "                                 test_bins,\n",
    "                                 gap_bins,\n",
    "                                 96,\n",
    "                                 hypo_thresh,\n",
    "                                 prevelance_ratio)\n",
    "\n",
    "# concatenate the data files, add label\n",
    "data_lab['id'] = np.arange(len(data_lab))\n",
    "\n",
    "# save out\n",
    "save_path = '/media/psf/Home/Documents/data/libre_labeled'\n",
    "np.savetxt(f\"{save_path}/labeledData_{train_bins}_trainBins_{test_bins}_testBins_{gap_bins}_gapBins_{hypo_thresh}_hypoThresh_{prevelance_ratio}_prevalenceRatio.csv\", data_lab, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ccf21924",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/pandas/core/frame.py:4138\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4137\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 4138\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4139\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m   4140\u001b[0m     \u001b[38;5;66;03m# This item wasn't present, just insert at end\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'id'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [162], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m new\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglu\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     14\u001b[0m new[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestep\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(new))\n\u001b[0;32m---> 15\u001b[0m \u001b[43mnew\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m       \u001b[38;5;241m=\u001b[39m i\n\u001b[1;32m     16\u001b[0m new[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]    \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     17\u001b[0m new\u001b[38;5;241m.\u001b[39massign(label \u001b[38;5;241m=\u001b[39m label)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/pandas/core/frame.py:3977\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3974\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3975\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3976\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 3977\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/pandas/core/frame.py:4184\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4181\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(existing_piece, DataFrame):\n\u001b[1;32m   4182\u001b[0m             value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(value, (\u001b[38;5;28mlen\u001b[39m(existing_piece\u001b[38;5;241m.\u001b[39mcolumns), \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m-> 4184\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/pandas/core/frame.py:4141\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4138\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4139\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m   4140\u001b[0m     \u001b[38;5;66;03m# This item wasn't present, just insert at end\u001b[39;00m\n\u001b[0;32m-> 4141\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iset_item_mgr(loc, value)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/pandas/core/internals/managers.py:1383\u001b[0m, in \u001b[0;36mBlockManager.insert\u001b[0;34m(self, loc, item, value)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;124;03mInsert item at selected position.\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1380\u001b[0m \u001b[38;5;124;03mvalue : np.ndarray or ExtensionArray\u001b[39;00m\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1382\u001b[0m \u001b[38;5;66;03m# insert to the axis; this could possibly raise a TypeError\u001b[39;00m\n\u001b[0;32m-> 1383\u001b[0m new_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1386\u001b[0m     value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/pandas/core/indexes/base.py:6940\u001b[0m, in \u001b[0;36mIndex.insert\u001b[0;34m(self, loc, item)\u001b[0m\n\u001b[1;32m   6938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor\u001b[38;5;241m.\u001b[39m_with_infer(new_values, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   6939\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 6940\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/pandas/core/indexes/base.py:716\u001b[0m, in \u001b[0;36mIndex._with_infer\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;124;03mConstructor that uses the 1.0.x behavior inferring numeric dtypes\u001b[39;00m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;124;03mfor ndarray[object] inputs.\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m--> 716\u001b[0m     \u001b[43mwarnings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilterwarnings\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mignore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.*the Index constructor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;167;43;01mFutureWarning\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m _dtype_obj \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_is_multi:\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"maybe_convert_objects\" has incompatible type\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;66;03m# \"ndarray[Any, Any]\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/warnings.py:155\u001b[0m, in \u001b[0;36mfilterwarnings\u001b[0;34m(action, message, category, module, lineno, append)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message:\n\u001b[0;32m--> 155\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mI\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/re.py:251\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompile\u001b[39m(pattern, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompile a regular expression pattern, returning a Pattern object.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/re.py:291\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compile\u001b[39m(pattern, flags):\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;66;03m# internal: compile pattern\u001b[39;00m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(flags, RegexFlag):\n\u001b[0;32m--> 291\u001b[0m         flags \u001b[38;5;241m=\u001b[39m \u001b[43mflags\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    293\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _cache[\u001b[38;5;28mtype\u001b[39m(pattern), pattern, flags]\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/types.py:176\u001b[0m, in \u001b[0;36mDynamicClassAttribute.__get__\u001b[0;34m(self, instance, ownerclass)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# support for abstract methods\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__isabstractmethod__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(fget, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__isabstractmethod__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__get__\u001b[39m(\u001b[38;5;28mself\u001b[39m, instance, ownerclass\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__isabstractmethod__:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# generate the features for analysis - by measurement and by day\n",
    "# convert to long format\n",
    "\n",
    "for i in range(0, data_lab.shape[0] + 1):\n",
    "    \n",
    "    if i%%100 == 0:\n",
    "        print(i / data_lab.shape[0])\n",
    "        \n",
    "    sub = data_lab[data_lab['id'] == i]\n",
    "    \n",
    "    label = sub['label']\n",
    "    sub   = sub.drop(['id', 'label'], axis=1)\n",
    "    \n",
    "    new   = sub.transpose()\n",
    "    new.columns = ['glu']\n",
    "    \n",
    "    new['timestep'] = np.arange(len(new))\n",
    "    new['id']       = i\n",
    "    new['label']    = 0\n",
    "    new.assign(label = label)\n",
    "    \n",
    "    for j in range(0, int(new.shape[0] / 96)):\n",
    "        j = j+1\n",
    "        c = np.repeat(j, 96)\n",
    "        if j==1:\n",
    "            cc = c\n",
    "        else:\n",
    "            cc = np.concatenate((cc, c))\n",
    "    \n",
    "    new['day_label'] = cc\n",
    "    \n",
    "    if i==0:\n",
    "        newcat=new\n",
    "    else:\n",
    "        frame = [newcat, new]\n",
    "        newcat = pd.concat(frame)\n",
    "    \n",
    " #    if i==1000:\n",
    "  #       break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "36584a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12050, 194)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4dcc1cc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [103], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdays\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      2\u001b[0m     c \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrepeat(j, \u001b[38;5;241m96\u001b[39m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(c)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "for j in range(1, days):\n",
    "    c = np.repeat(j, 96)\n",
    "    print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dba9a5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a1447f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, n_files+1):\n",
    "    # print(i)\n",
    "    sub = pd.read_csv(f\"/media/psf/Home/Documents/data/libre_as_supervised/supervised_{i}_{train_bins}_{outVal}_vals.csv\",\n",
    "                 nrows = None, header = None)\n",
    "    \n",
    "    if i==1:\n",
    "        concat_output = sub\n",
    "    else:\n",
    "        frames = [concat_output, sub]\n",
    "        concat_output = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "61537f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1104107, 288)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "35463e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take every nth row; where n = test_bins\n",
    "all_data = concat_output.iloc[::test_bins, :]\n",
    "\n",
    "# divide into train and test splits (cols)\n",
    "train_cols = all_data.iloc[:, 0:train_bins]\n",
    "test_cols  = all_data.iloc[:, train_bins:train_bins + test_bins + gap_bins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "55823a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69007, 288)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e54c286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels\n",
    "minvalue = test_cols.min(axis = 1)\n",
    "label = np.where(minvalue < hypo_thresh, 1, 0)\n",
    "\n",
    "df_X = train_cols.copy()\n",
    "df_X['label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d9c77333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69007, 193)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "48b6656b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# downsample to a specified ratio of case:control\n",
    "df_X_case = df_X[label==1]\n",
    "df_X_control = df_X[label==0]\n",
    "\n",
    "sample = df_X_control.sample(n=(df_X_case.shape[0] * prevelance_ratio))\n",
    "\n",
    "frame = [df_X_case, sample]\n",
    "output_frame = pd.concat(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "07730d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2410, 193)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_case.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2a56514f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12050, 193)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51208c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
