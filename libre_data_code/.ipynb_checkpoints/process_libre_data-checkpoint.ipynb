{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51fe9044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "807f4f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols = list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc5b94b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_transform(load_path, save_path, inVal_unit, outVal, days_of_training = 4, rowLimit = None):\n",
    "    \n",
    "    libre_files = glob.glob(f\"{load_path}/*\")\n",
    "    print(len(libre_files))\n",
    "    \n",
    "    file_n = 1\n",
    "    \n",
    "    for f in libre_files:\n",
    "        print(f)\n",
    "        series = read_csv(f, header=0, index_col=1, nrows = rowLimit)\n",
    "        values = series.values\n",
    "\n",
    "        # values = values[0:20000]\n",
    "\n",
    "        for j in range(1, (days_of_training + 1)):\n",
    "            # transform the time series data into supervised learning\n",
    "            inVal  = inVal_unit*j\n",
    "            outVal = outVal\n",
    "            data = series_to_supervised(values, n_in=inVal, n_out = outVal)\n",
    "\n",
    "            # save out data as supervised data format\n",
    "            np.savetxt(f\"{save_path}/supervised_{file_n}_{inVal}_{outVal}_vals.csv\", data, delimiter=\",\")\n",
    "\n",
    "        file_n = file_n + 1\n",
    "        \n",
    "    return(len(libre_files))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67833e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_labeled_data(load_path, rowLimit, n_files, train_bins, test_bins, gap_bins, outVal, hypo_thresh, prevelance_ratio):\n",
    "    \n",
    "    for i in range(1, n_files+1):\n",
    "        # print(i)\n",
    "        sub = pd.read_csv(f\"{load_path}/supervised_{i}_{train_bins}_{outVal}_vals.csv\",\n",
    "                     nrows = rowLimit, header = None)\n",
    "\n",
    "        if i==1:\n",
    "            concat_output = sub\n",
    "        else:\n",
    "            frames = [concat_output, sub]\n",
    "            concat_output = pd.concat(frames)\n",
    "            \n",
    "    print(concat_output.shape)\n",
    "    \n",
    "    # take every nth row; where n = test_bins\n",
    "    all_data = concat_output.iloc[::test_bins, :]\n",
    "\n",
    "    # divide into train and test splits (cols)\n",
    "    train_cols = all_data.iloc[:, 0:train_bins]\n",
    "    test_cols  = all_data.iloc[:, train_bins:train_bins + test_bins + gap_bins]\n",
    "    \n",
    "    # create labels\n",
    "    minvalue = test_cols.min(axis = 1)\n",
    "    label = np.where(minvalue < hypo_thresh, 1, 0)\n",
    "\n",
    "    df_X = train_cols.copy()\n",
    "    df_X['label'] = label\n",
    "    \n",
    "    # downsample to a specified ratio of case:control\n",
    "    df_X_case = df_X[label==1]\n",
    "    df_X_control = df_X[label==0]\n",
    "\n",
    "    sample = df_X_control.sample(n=(df_X_case.shape[0] * prevelance_ratio))\n",
    "\n",
    "    frame = [df_X_case, sample]\n",
    "    output_frame = pd.concat(frame)\n",
    "    \n",
    "    return(output_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6200c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_6.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_7.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_5.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_4.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_1.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_3.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_2.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_14.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_15.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_11.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_10.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_12.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_13.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_9.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_8.csv\n"
     ]
    }
   ],
   "source": [
    "# transform a time series dataset into a supervised learning dataset\n",
    "# return the number of source files (sourceFile_n)\n",
    "# (ie individuals libre data in the processed raw data folder (load_path))\n",
    "sourceFile_n = load_and_transform(load_path = \"/media/psf/Home/Documents/data/processed_libre\",\n",
    "                  save_path = \"/media/psf/Home/Documents/data/libre_as_supervised2\",\n",
    "                  inVal_unit = 96,\n",
    "                  outVal = 96,\n",
    "                  days_of_training = 4,\n",
    "                  rowLimit = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aad2c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the supervised files and concatenate into a single file\n",
    "# select by nth row to avoid overfitting / data leakage from one training set into another\n",
    "# take interval to be duration of test window\n",
    "# add progressive gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70e6b864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1104107, 288)\n"
     ]
    }
   ],
   "source": [
    "# set variables\n",
    "sourceFile_n = 15 # if all cells not run above ie if starting here need to set this\n",
    "\n",
    "n_files = sourceFile_n\n",
    "\n",
    "test_duration_hours = 4\n",
    "gap_hours = 0\n",
    "\n",
    "train_bins = 192\n",
    "test_bins = test_duration_hours * 4\n",
    "gap_bins = gap_hours * 4\n",
    "\n",
    "hypo_thresh = 3\n",
    "\n",
    "prevelance_ratio = 4\n",
    "\n",
    "# concatenate the data files, add label\n",
    "data_lab = generate_labeled_data(\"/media/psf/Home/Documents/data/libre_as_supervised\",\n",
    "                                 None,\n",
    "                                 n_files,\n",
    "                                 train_bins,\n",
    "                                 test_bins,\n",
    "                                 gap_bins,\n",
    "                                 96,\n",
    "                                 hypo_thresh,\n",
    "                                 prevelance_ratio)\n",
    "\n",
    "# concatenate the data files, add label\n",
    "data_lab['id'] = np.arange(len(data_lab))\n",
    "\n",
    "# save out\n",
    "save_path = '/media/psf/Home/Documents/data/libre_labeled'\n",
    "np.savetxt(f\"{save_path}/labeledData_{train_bins}_trainBins_{test_bins}_testBins_{gap_bins}_gapBins_{hypo_thresh}_hypoThresh_{prevelance_ratio}_prevalenceRatio.csv\", data_lab, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3b4e3e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the features for analysis - by measurement and by day\n",
    "# convert to long format\n",
    "\n",
    "for i in range(0, data_lab.shape[1] + 1):\n",
    "    \n",
    "    sub = data_lab[data_lab['id'] == i]\n",
    "    \n",
    "    label = sub['label']\n",
    "    sub   = sub.drop(['id', 'label'], axis=1)\n",
    "    \n",
    "    new   = sub.transpose()\n",
    "    new.columns = ['glu']\n",
    "    \n",
    "    new['timestep'] = np.arange(len(new))\n",
    "    new['id']       = i\n",
    "    new['label']    = 0\n",
    "    new.assign(label = label)\n",
    "    \n",
    "    for j in range(0, int(new.shape[0] / 96)):\n",
    "        j = j+1\n",
    "        c = np.repeat(j, 96)\n",
    "        if j==1:\n",
    "            cc = c\n",
    "        else:\n",
    "            cc = np.concatenate((cc, c))\n",
    "    \n",
    "    new['day_label'] = cc\n",
    "    \n",
    "    if i==0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bfa3fd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glu</th>\n",
       "      <th>timestep</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>day_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.26875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.22500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.18125</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.13750</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.09375</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>7.90000</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>7.00000</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>6.40000</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>6.30000</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>5.90000</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         glu  timestep  id  label  day_label\n",
       "0    6.26875         0   0      0          1\n",
       "1    6.22500         1   0      0          1\n",
       "2    6.18125         2   0      0          1\n",
       "3    6.13750         3   0      0          1\n",
       "4    6.09375         4   0      0          1\n",
       "..       ...       ...  ..    ...        ...\n",
       "187  7.90000       187   0      0          2\n",
       "188  7.00000       188   0      0          2\n",
       "189  6.40000       189   0      0          2\n",
       "190  6.30000       190   0      0          2\n",
       "191  5.90000       191   0      0          2\n",
       "\n",
       "[192 rows x 5 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cd7bbe24",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [103], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdays\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      2\u001b[0m     c \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrepeat(j, \u001b[38;5;241m96\u001b[39m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(c)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "for j in range(1, days):\n",
    "    c = np.repeat(j, 96)\n",
    "    print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9af6ddf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a1447f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, n_files+1):\n",
    "    # print(i)\n",
    "    sub = pd.read_csv(f\"/media/psf/Home/Documents/data/libre_as_supervised/supervised_{i}_{train_bins}_{outVal}_vals.csv\",\n",
    "                 nrows = None, header = None)\n",
    "    \n",
    "    if i==1:\n",
    "        concat_output = sub\n",
    "    else:\n",
    "        frames = [concat_output, sub]\n",
    "        concat_output = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "61537f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1104107, 288)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "35463e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take every nth row; where n = test_bins\n",
    "all_data = concat_output.iloc[::test_bins, :]\n",
    "\n",
    "# divide into train and test splits (cols)\n",
    "train_cols = all_data.iloc[:, 0:train_bins]\n",
    "test_cols  = all_data.iloc[:, train_bins:train_bins + test_bins + gap_bins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "55823a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69007, 288)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e54c286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels\n",
    "minvalue = test_cols.min(axis = 1)\n",
    "label = np.where(minvalue < hypo_thresh, 1, 0)\n",
    "\n",
    "df_X = train_cols.copy()\n",
    "df_X['label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d9c77333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69007, 193)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "48b6656b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# downsample to a specified ratio of case:control\n",
    "df_X_case = df_X[label==1]\n",
    "df_X_control = df_X[label==0]\n",
    "\n",
    "sample = df_X_control.sample(n=(df_X_case.shape[0] * prevelance_ratio))\n",
    "\n",
    "frame = [df_X_case, sample]\n",
    "output_frame = pd.concat(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "07730d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2410, 193)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_case.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2a56514f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12050, 193)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51208c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
