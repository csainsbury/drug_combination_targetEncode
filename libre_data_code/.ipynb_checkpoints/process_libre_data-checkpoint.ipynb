{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51fe9044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "807f4f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform a time series dataset into a supervised learning dataset\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols = list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8941bd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_transform(load_path, save_path, inVal_unit, outVal, days_of_training = 4, rowLimit = None):\n",
    "    \n",
    "    libre_files = glob.glob(f\"{load_path}/*\")\n",
    "    print(len(libre_files))\n",
    "    \n",
    "    file_n = 1\n",
    "    \n",
    "    for f in libre_files:\n",
    "        print(f)\n",
    "        series = read_csv(f, header=0, index_col=1, nrows = rowLimit)\n",
    "        values = series.values\n",
    "\n",
    "        # values = values[0:20000]\n",
    "\n",
    "        for j in range(1, (days_of_training + 1)):\n",
    "            # transform the time series data into supervised learning\n",
    "            inVal  = inVal_unit*j\n",
    "            outVal = outVal\n",
    "            data = series_to_supervised(values, n_in=inVal, n_out = outVal)\n",
    "\n",
    "            # save out data as supervised data format\n",
    "            np.savetxt(f\"{save_path}/supervised_{file_n}_{inVal}_{outVal}_vals.csv\", data, delimiter=\",\")\n",
    "\n",
    "        file_n = file_n + 1\n",
    "        \n",
    "    return(len(libre_files))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44553dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_labeled_data(load_path, rowLimit, n_files, train_bins, test_bins, gap_bins, outVal, hypo_thresh, prevelance_ratio):\n",
    "    \n",
    "    for i in range(1, n_files+1):\n",
    "        # print(i)\n",
    "        sub = pd.read_csv(f\"{load_path}/supervised_{i}_{train_bins}_{outVal}_vals.csv\",\n",
    "                     nrows = rowLimit, header = None)\n",
    "\n",
    "        if i==1:\n",
    "            concat_output = sub\n",
    "        else:\n",
    "            frames = [concat_output, sub]\n",
    "            concat_output = pd.concat(frames)\n",
    "            \n",
    "    print(concat_output.shape)\n",
    "    \n",
    "    # take every nth row; where n = test_bins\n",
    "    all_data = concat_output.iloc[::test_bins, :]\n",
    "\n",
    "    # divide into train and test splits (cols)\n",
    "    train_cols = all_data.iloc[:, 0:train_bins]\n",
    "    test_cols  = all_data.iloc[:, train_bins:train_bins + test_bins + gap_bins]\n",
    "    \n",
    "    # create labels\n",
    "    minvalue = test_cols.min(axis = 1)\n",
    "    label = np.where(minvalue < hypo_thresh, 1, 0)\n",
    "\n",
    "    df_X = train_cols.copy()\n",
    "    df_X['label'] = label\n",
    "    \n",
    "    # downsample to a specified ratio of case:control\n",
    "    df_X_case = df_X[label==1]\n",
    "    df_X_control = df_X[label==0]\n",
    "\n",
    "    sample = df_X_control.sample(n=(df_X_case.shape[0] * prevelance_ratio))\n",
    "\n",
    "    frame = [df_X_case, sample]\n",
    "    output_frame = pd.concat(frame)\n",
    "    \n",
    "    return(output_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b33d7e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_6.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_7.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_5.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_4.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_1.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_3.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_2.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_14.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_15.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_11.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_10.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_12.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_13.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_9.csv\n",
      "/media/psf/Home/Documents/data/processed_libre/proc_8.csv\n"
     ]
    }
   ],
   "source": [
    "# transform a time series dataset into a supervised learning dataset\n",
    "# return the number of source files (sourceFile_n)\n",
    "# (ie individuals libre data in the processed raw data folder (load_path))\n",
    "sourceFile_n = load_and_transform(load_path = \"/media/psf/Home/Documents/data/processed_libre\",\n",
    "                  save_path = \"/media/psf/Home/Documents/data/libre_as_supervised2\",\n",
    "                  inVal_unit = 96,\n",
    "                  outVal = 96,\n",
    "                  days_of_training = 4,\n",
    "                  rowLimit = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aad2c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the supervised files and concatenate into a single file\n",
    "# select by nth row to avoid overfitting / data leakage from one training set into another\n",
    "# take interval to be duration of test window\n",
    "# add progressive gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b016ea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables\n",
    "n_files = sourceFile_n\n",
    "\n",
    "test_duration_hours = 4\n",
    "gap_hours = 0\n",
    "\n",
    "train_bins = 192\n",
    "test_bins = test_duration_hours * 4\n",
    "gap_bins = gap_hours * 4\n",
    "\n",
    "hypo_thresh = 3\n",
    "\n",
    "prevelance_ratio = 4\n",
    "\n",
    "# concatenate the data files, add label\n",
    "data_lab = generate_labeled_data(\"/media/psf/Home/Documents/data/libre_as_supervised\",\n",
    "                                 None,\n",
    "                                 n_files,\n",
    "                                 train_bins,\n",
    "                                 test_bins,\n",
    "                                 gap_bins,\n",
    "                                 96,\n",
    "                                 hypo_thresh,\n",
    "                                 prevelance_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9cddf9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3182, 193)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "139d2e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, n_files+1):\n",
    "    # print(i)\n",
    "    sub = pd.read_csv(f\"/media/psf/Home/Documents/data/libre_as_supervised/supervised_{i}_{train_bins}_{outVal}_vals.csv\",\n",
    "                 nrows = None, header = None)\n",
    "    \n",
    "    if i==1:\n",
    "        concat_output = sub\n",
    "    else:\n",
    "        frames = [concat_output, sub]\n",
    "        concat_output = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "78affdc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1104107, 288)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "e040848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take every nth row; where n = test_bins\n",
    "all_data = concat_output.iloc[::test_bins, :]\n",
    "\n",
    "# divide into train and test splits (cols)\n",
    "train_cols = all_data.iloc[:, 0:train_bins]\n",
    "test_cols  = all_data.iloc[:, train_bins:train_bins + test_bins + gap_bins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8d8abfde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69007, 288)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3e4e46b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels\n",
    "minvalue = test_cols.min(axis = 1)\n",
    "label = np.where(minvalue < hypo_thresh, 1, 0)\n",
    "\n",
    "df_X = train_cols.copy()\n",
    "df_X['label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1d894f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69007, 193)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "54012eba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# downsample to a specified ratio of case:control\n",
    "df_X_case = df_X[label==1]\n",
    "df_X_control = df_X[label==0]\n",
    "\n",
    "sample = df_X_control.sample(n=(df_X_case.shape[0] * prevelance_ratio))\n",
    "\n",
    "frame = [df_X_case, sample]\n",
    "output_frame = pd.concat(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "c921deb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2410, 193)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_case.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "79aac9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12050, 193)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6a80a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
